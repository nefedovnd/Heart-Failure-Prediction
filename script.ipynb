{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## About the project"
      ],
      "metadata": {
        "id": "I2U8THos5U_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I will use a dataset from [Kaggle](https://www.kaggle.com/datasets/andrewmvd/heart-failure-clinical-data) to predict the survival of patients with heart failure from serum creatinine and ejection fraction, and other factors such as age, anemia, diabetes, and so on.\n",
        "\n",
        "This project is a part of Codecademy Build Deep Learning Models with TensorFlow Skill Path."
      ],
      "metadata": {
        "id": "VBdvAVQg4xA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data"
      ],
      "metadata": {
        "id": "XE-hRBP45bWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "4lq8wgC15iwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "u9bi10HG5nJK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data from `heart_failure.csv` to a pandas DataFrame object. Assign the resulting DataFrame to a variable called data"
      ],
      "metadata": {
        "id": "L9XDrWS_5xoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"heart_failure_clinical_records_dataset.csv\")"
      ],
      "metadata": {
        "id": "Y5NLKqxD5z8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the distribution of the `death_event` column in the data DataFrame class using collections.Counter. This is the column you will need to predict."
      ],
      "metadata": {
        "id": "LzZUJir258jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print('Classes and number of values in the dataset', Counter(data['death_event']))"
      ],
      "metadata": {
        "id": "o4ELKmIl6BI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the label column death_event from the data DataFrame and assign the result to a variable called `y`"
      ],
      "metadata": {
        "id": "wHPaHD7E6Ex4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = data.iloc[:, -1]\n",
        "#or y = data[\"death_event\"]"
      ],
      "metadata": {
        "id": "jJ7vltky6JiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the features columns `['age','anaemia','creatinine_phosphokinase','diabetes','ejection_fraction','high_blood_pressure','platelets','serum_creatinine','serum_sodium','sex','smoking','time']` from the DataFrame instance data and assign the result to a variable called `x`"
      ],
      "metadata": {
        "id": "uARBf3S56Q2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = data[['age','anaemia','creatinine_phosphokinase','diabetes','ejection_fraction','high_blood_pressure','platelets','serum_creatinine','serum_sodium','sex','smoking','time']]"
      ],
      "metadata": {
        "id": "bn9sAhUA6Y9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "PxfchznV7Nvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `pandas.get_dummies()` function to convert the categorical features in the DataFrame instance `x` to one-hot encoding vectors and assign the result back to variable `x`."
      ],
      "metadata": {
        "id": "_OQ32ajx6qtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.get_dummies(x)"
      ],
      "metadata": {
        "id": "VKyHEvO76wW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `sklearn.model_selection.train_test_split()` method to split the data into training features, test features, training labels, and test labels, respectively. To the `test_size` parameter assign the percentage of data to put in the test data, and use value for the `random_state` parameter. Store the results of the function to `X_train`, `X_test`, `Y_train`, `Y_test` variables."
      ],
      "metadata": {
        "id": "s-umnYE76y16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)"
      ],
      "metadata": {
        "id": "JIFseQcp61oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize a ColumnTransformer object by using StandardScaler to scale the numeric features in the dataset: `['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']`. Assign the resulting object to a variable called `ct`"
      ],
      "metadata": {
        "id": "MLmVIRuz7HWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "ct = ColumnTransformer([(\"numeric\", Normalizer(), ['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time'])])"
      ],
      "metadata": {
        "id": "lOywURIE7XJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `ColumnTransformer.fit_transform()` function to train the scaler instance ct on the training data `X_train` and assign the result back to `X_train`."
      ],
      "metadata": {
        "id": "NI435Mgy7Z2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = ct.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "bRCf-jiy7ia1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `ColumnTransformer.transform()` to scale the test data instance `X_test` using the trained scaler ct, and assign the result back to `X_test`."
      ],
      "metadata": {
        "id": "XoF4ArLf7kvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = ct.transform(X_test)"
      ],
      "metadata": {
        "id": "lO_46VUS7sFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare labels for classification"
      ],
      "metadata": {
        "id": "UPi6SrsN7s2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize an instance of `LabelEncoder` and assign it to a variable called `le`."
      ],
      "metadata": {
        "id": "Tts8_H_57vs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()"
      ],
      "metadata": {
        "id": "aUiC7KDW70b2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `LabelEncoder.fit_transform()` function, fit the encoder instance le to the training labels `Y_train`, while at the same time converting the training labels according to the trained encoder."
      ],
      "metadata": {
        "id": "5HP8aMf-75lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = le.fit_transform(Y_train.astype(str))"
      ],
      "metadata": {
        "id": "dYm0asKo78Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `LabelEncoder.transform() function`, encode the test labels `Y_test` using the trained encoder le."
      ],
      "metadata": {
        "id": "oO3qtlFa79cK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test = le.fit_transform(Y_test.astype(str))"
      ],
      "metadata": {
        "id": "s4YOVNBM8BQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `tensorflow.keras.utils.to_categorical()` function, transform the encoded training labels `Y_train` into a binary vector and assign the result back to `Y_train`."
      ],
      "metadata": {
        "id": "kB0t94Rl8Cf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "Y_train = to_categorical(Y_train)"
      ],
      "metadata": {
        "id": "rras7Src8HxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the tensorflow.keras.utils.`to_categorical()` function, transform the encoded test labels `Y_test` into a binary vector and assign the result back to `Y_test`."
      ],
      "metadata": {
        "id": "7pL2Umz_8PAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test = to_categorical(Y_test)"
      ],
      "metadata": {
        "id": "PITbUHDL8TEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Design the model"
      ],
      "metadata": {
        "id": "4iH9KDDp8XkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize a `tensorflow.keras.models.Sequential` model instance called model."
      ],
      "metadata": {
        "id": "8e0N7Fl78ac5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "_CunNhdr8cpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an input layer instance of `tensorflow.keras.layers.InputLayer` and add it to the model instance model using the `Model.add()` function."
      ],
      "metadata": {
        "id": "1eszTIWf8f_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(InputLayer(input_shape=(X_train.shape[1],)))"
      ],
      "metadata": {
        "id": "ogBjHrbz8mY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a hidden layer instance of `tensorflow.keras.layers.Dense` with relu activation function and 12 hidden neurons, and add it to the model instance model."
      ],
      "metadata": {
        "id": "MDf4s4jJ8n76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(12, activation='relu'))"
      ],
      "metadata": {
        "id": "RCOIL9R98rtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an output layer instance of `tensorflow.keras.layers.Dense` with a softmax activation function (because of classification) with the number of neurons corresponding to the number of classes in the dataset."
      ],
      "metadata": {
        "id": "wGZSHmKW8tcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "CiafdIkx8w_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `Model.compile()` function, compile the model instance model using the `categorical_crossentropy` loss, adam optimizer and accuracy as metrics."
      ],
      "metadata": {
        "id": "7CL0NuAi8y9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "tnzjOapA8567"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and evaluate the model"
      ],
      "metadata": {
        "id": "agOJ8pRi87l5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `Model.fit()` function, fit the model instance model to the training data `X_train` and training labels `Y_train`. Set the number of epochs to 100 and the batch size parameter to 16."
      ],
      "metadata": {
        "id": "fX3CqiTZ9AHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs = 100, batch_size = 16, verbose=1)"
      ],
      "metadata": {
        "id": "4xUhsB7c9EmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `Model.evaluate()` function, evaluate the trained model instance model on the test data `X_test` and test labels `Y_test`. Assign the result to a variable called loss (representing the final loss value) and a variable called acc (representing the accuracy metrics), respectively."
      ],
      "metadata": {
        "id": "chR0cldy9GUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Loss\", loss, \"Accuracy:\", acc)"
      ],
      "metadata": {
        "id": "sqVIhkP29KpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating a classification report"
      ],
      "metadata": {
        "id": "4l5e7ABs9Mcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `Model.predict()` to get the predictions for the test data `X_test` with the trained model instance model. Assign the result to a variable called `y_estimate`."
      ],
      "metadata": {
        "id": "fmTWJPzY9PrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_estimate = model.predict(X_test, verbose=0)"
      ],
      "metadata": {
        "id": "2SDyUj9N9Vq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `numpy.argmax()` method to select the indices of the true classes for each label encoding in `y_estimate`. Assign the result to a variable called `y_estimate`."
      ],
      "metadata": {
        "id": "q2rWAKCT9YA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_estimate = np.argmax(y_estimate, axis=1)"
      ],
      "metadata": {
        "id": "5AOkZg4-9bov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `numpy.argmax()` method to select the indices of the true classes for each label encoding in `Y_test`. Assign the result to a variable called `y_true`."
      ],
      "metadata": {
        "id": "bEtcTHoy9eUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.argmax(Y_test, axis=1)"
      ],
      "metadata": {
        "id": "NcoGYmT39iUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print additional metrics, such as F1-score, using the `sklearn.metrics.classification_report()` function by providing it with `y_true` and `y_estimate` vectors as input parameters."
      ],
      "metadata": {
        "id": "le8lxHAl9jqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_estimate))"
      ],
      "metadata": {
        "id": "I0Y_R3Yq9tBk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
